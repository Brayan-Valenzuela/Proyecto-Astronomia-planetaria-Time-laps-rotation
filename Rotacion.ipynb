{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2          #Libreria de vision artificial\n",
    "import os           #Trabajar con informacion del sistema operativo\n",
    "import numpy as np  #Operaciones matriciales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el total de fotogramas es: 216\n"
     ]
    }
   ],
   "source": [
    "def extraer_fotogramas(video):                  #Funcion creada para extraer cada fotograma y guardarlos\n",
    "                                                #y guardarlos en una lista\n",
    "    ruta_actual   = os.getcwd()                     #Cargamos la ruta donde se encuentra el proyecto\n",
    "    fotogramas    = []                              #Lista dedicada a contener los fotogramas\n",
    "\n",
    "    vidcap        = cv2.VideoCapture(ruta_actual+'/'+video) #Creacion de objeto video capture\n",
    "    success,image = vidcap.read()                           #Se lee el primer fotograma\n",
    "    count         = 0                                       #Se establece un contador\n",
    "\n",
    "    while success:                                          #El Objeto video capture controla la extraccion \n",
    "        fotogramas.append(image)                            #Se guarda el frame\n",
    "        success,image = vidcap.read()                       #Se pregunta por los siguientes \n",
    "        count        += 1                                   #Se aumenta el contador\n",
    "\n",
    "    return fotogramas\n",
    "\n",
    "fotogramas = extraer_fotogramas('time_laps3.mp4')\n",
    "print('el total de fotogramas es:', len(fotogramas)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esta celda se encuentra la fucnion tomada de: https://www.learnopencv.com/image-alignment-feature-based-â€¦/\n",
    "#Ingresan dos imagenes en formato \"NDARRAY\" el fotograma a alinear y el fotograma de referencia\n",
    "#Retorna dos \"NDARRAY\" una con la imagen alineada y los match que hizo para alinearla\n",
    "MAX_FEATURES = 5000000\n",
    "GOOD_MATCH_PERCENT = 0.5\n",
    " \n",
    "def alignImages(im1, im2):\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ORB features and compute descriptors.\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    # Remove not so good matches\n",
    "    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:numGoodMatches]\n",
    "\n",
    "    # Draw top matches\n",
    "    imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "    #cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return im1Reg,imMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alinear(fotogramas):\n",
    "    \n",
    "    alineados = []                                              #Lista para guardar alineaciones\n",
    "    matches = []                                                #Lista para guardar matches\n",
    "    referencia = fotogramas[-1]                                 #Se toma el ultimo cuadro como referencia\n",
    "\n",
    "    for fotograma in fotogramas:                                #Se iteran todos los fotogramas\n",
    "        alineado, match = alignImages(fotograma, referencia)    #Se hace la alineacion\n",
    "        matches.append(match)                                   #Se guardan los matches\n",
    "        alineados.append(alineado)                              #Se guarda alineados\n",
    "    \n",
    "    return alineados                                            #Se retornan los fotogramas alineados\n",
    "\n",
    "alineados = alinear(fotogramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_cuadros(fotogramas, alineados):\n",
    "    \n",
    "    dim = np.shape(fotogramas[0])                              #Se guardan las dimensiones individuales de cada fotograma\n",
    "    unidos = []                                                #Lista para guardar los cuadros concatenados\n",
    "    \n",
    "    for i, fotograma in enumerate(fotogramas):                 #Se iteran los fotogramas\n",
    "\n",
    "        fotograma1 = alineados[i]                              \n",
    "        unidos.append(np.concatenate((fotograma,fotograma1)))  #Se concatenana los fotogramas originales con los alineados y se guardan\n",
    "        \n",
    "    return unidos\n",
    "\n",
    "unidos = juntar_cuadros(fotogramas, alineados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armar_video(unidos):\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')                 #Formato del video\n",
    "    dim1 = np.shape(unidos[0])                                          #Dimensiones de espaciales del video\n",
    "    out = cv2.VideoWriter('matches.mp4',fourcc, 15, (dim1[1], dim1[0])) #Se crea el objeto para escribir el video\n",
    "\n",
    "    for match in unidos:                                                #Se iteran los cuadros\n",
    "        out.write(match)                                                #Se guardan\n",
    "    out.release()                                                       #Se libera el objeto\n",
    "    \n",
    "armar_video(unidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
